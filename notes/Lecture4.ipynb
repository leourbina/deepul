{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Lecture4.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"UrZgC21U2y7C"},"source":["# Lecture 4 - Latent Variable Models"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"YcF-yxUo2y7D"},"source":["# Overview\n","\n","TL;DR:\n","\n","\n","We want to be able to model a rich space $x$ (e.g. images of bedrooms) using a **latent** represantion $z \\sim p_Z(z)$ (naive: how many beds, lamps, windows, etc) that we pick:\n","\n","<img src=\"https://www.evernote.com/l/AguDzvDhelxOXZxCuQdAEcuxqmJ47bQU_LwB/image.png\" alt=\"drawing\" width=\"150\"/>\n","\n","\n","* **VLB/ELBO** can be used as a more manageable objective. "]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"7NjXfXvwp6rS"},"source":["## Sample\n","\n","$$ z \\sim p_Z(z) $$\n","$$ x \\sim p_\\theta(x | z) $$\n","## Evaluate likelihood\n","\n","$$ p_\\theta(x) = \\sum_z p_Z(z)p_\\theta(x | z) $$\n","\n","## Train\n","\n","We use MLE as usual. Objective is:\n","\n","$$\\max_\\theta\\sum_i \\log p_\\theta(x^{(i)}) = \n","\\max_\\theta \\sum_i \\log \\sum_z p_Z(z)p_\\theta(x^{(i)} | z)$$\n","## Representation \n","\n","$$ x \\rightarrow z $$\n","\n","If $z$ is the compact representation of our data, we usually we want to be able to go in the opposite direction. We should be able to do this using Baye's rule:\n","\n","$$ p_\\theta(z | x) = \\frac{p_\\theta(x | z) p_Z(z)}{p_\\theta(x) }$$\n","\n","Although, it is not always tractable to do this.\n","## Notes\n","\n","* Difference from Flow Models: Flow models assume that x and z have the same dimensionality, so that the flow is a biyection.\n","## It's all about how big the $Z$ space is\n","\n","If the $Z$ space is small enough, say, when $z$ takes a small number of discrete values. E.g. \n","\n","$$z \\in {A, B, C}  \\\\\n","p_Z(z = A) = p_Z(z = B) = p_Z(z = C) = \\frac13  \\\\\n","p_\\theta(x | z = k) = \\frac{1}{(2\\pi)^{\\frac{n}{2}}\\left|\\Sigma_k\\right|^{\\frac12}}\\exp\\left(-\\frac12(x - \\mu_k)^\\top\\Sigma_k^{-1}(x - \\mu_k)\\right)\n","$$\n","\n","### Training objective is \n","\n","$$ \\max_\\theta\\sum_i\\log p_\\theta(x^{(i)}) \\\\\n","= \\max_{\\mu, \\Sigma}\\sum_i \\log\\left[ \n","\\frac13 \\frac{1}{(2\\pi)^{\\frac{n}{2}}\\left|\\Sigma_A\\right|^{\\frac12}}\\exp\\left(-\\frac12(x - \\mu_A)^\\top\\Sigma_A^{-1}(x - \\mu_A)\\right) + \\\\ \n","\\frac13 \\frac{1}{(2\\pi)^{\\frac{n}{2}}\\left|\\Sigma_B\\right|^{\\frac12}}\\exp\\left(-\\frac12(x - \\mu_B)^\\top\\Sigma_B^{-1}(x - \\mu_B)\\right) + \\\\ \n","\\frac13 \\frac{1}{(2\\pi)^{\\frac{n}{2}}\\left|\\Sigma_C\\right|^{\\frac12}}\\exp\\left(-\\frac12(x - \\mu_C)^\\top\\Sigma_C^{-1}(x - \\mu_C)\\right) \\right]$$\n","This objective can be evaluated for each training point, and we can feed this to an optimizer (SGD, etc)\n","\n","## What happens when the $Z$ space is big? \n","\n","Then the sum\n","\n","$$p(x^{(i)}) = \\sum_z p_Z(z)p_\\theta(x^{(i)} | z)$$\n","\n","Cannot be evaluated exactly. Instead we approximate it\n","\n","$$\\sum_z p_Z(z)p_\\theta(x^{(i)} | z) = \n","\\mathop{\\mathbb{E}}_{z \\sim Z} p_\\theta(x^{(i)} | z)\\\\\\approx \n","\\frac1K \\sum_{k=1}^{K}p_\\theta(x^{(i)} | z_k^{(i)})$$\n","Our objective becomes\n","\n","$$ \\max_\\theta \\sum_i \\log \\frac1K \\sum_{k=1}^{K}p_\\theta(x^{(i)} | z_k^{(i)}) $$\n","\n","So for every $x^{(i)}$ we'll be sampling $K$ $z$'s\n","## [Prior Sampling Challenge](https://youtu.be/FMuvUZXMzKM)\n","\n","Let's say our data $x$ is in N gaussian clusters, and we're fitting a mixture of gaussians, where $z$ determines which gaussian we sample. \n","\n","Sampling $z$ from our mixture uniformly results in only $\\frac1N$ of the terms (i.e. $p_\\theta(x | z)$) being considerable contributions, the others are very close to 0 (as $z$ and $x^{(i)}$ are in different modes, and their gradients are very close to 0. \n","\n","<img src=\"https://www.evernote.com/l/AgsJsb70fnRFKI_hYjcsbLJDX9cfvlD-9EsB/image.png\" alt=\"drawing\" width=\"500\"/>\n","\n","In high dimensions it becomes near impossible to get \"lucky\" enough that the sampled $z$ is a good match for the training point $x$\n","\n","# Importance Sampling\n","\n","Want to compute \n","\n","$$\\mathbb{E}_{z \\sim p_Z(z)}f(z)$$\n","But (1) hard to sample from $p_Z(z)$, and/or samples from $p_Z(z)$ are not very informative (e.g. the example of N gaussian clusters)\n","## Main idea\n","\n","$$\\mathbb{E}_{z \\sim p_Z(z)}f(z) = \n","\\sum_z p_Z(z) f(z) \\\\\n","= \\sum_z \\frac{q(z)}{q(z)}p_Z(z)f(z) \\\\\n","= \\mathbb{E}_{z \\sim q(z)} \\left[\\frac{p_z(z)}{q(z)}f(z) \\right] \\\\\n","\\approx \\frac1K\\sum_{k=1}^K \\frac{p_Z(z^{(k)})}{q(z^{(k)})}f(z^{(k)})$$\n","\n","With $z^{(k)} \\sim q(z)$. We can now sample from $q$ to compute expectation w.r.t $p$\n","### Importance Sampled Objective\n","\n","$$\\sum_i \\log \\sum_z p_Z(z)p_\\theta(x^{(i)} | z) \n","\\approx \\sum_i \\log \\frac1K\\sum_{k=1}^K \\frac{p_Z(z^{(i)}_k)}{q(z^{(i)}_k)}p_\\theta(x^{(i)} | z_k^{(i)}) $$\n","\n","With $z_k^{(i)} \\sim q(z_k^{(i)})$\n","## How to pick $q(z)$ ?\n","\n","**Need to find distribution $q(z)$ that tells us which $z$ are likely given our data $x^{(i)}$**. This is like learning the reverse mapping $x^{(i)} \\rightarrow z$\n","\n","How about \n","\n","$$ q(z) = p_\\theta(z | x^{(i)}) = \\frac{p(x^{(i)} | z)p_Z(z)}{p_\\theta(x^{(i)})} $$\n","\n","**Issue:** Unclear how to sample from this. From our assumption it is not tractable to compute the denominator (marginalizing over all $z$s is hard)\n","\n","## Variational Approach\n","\n","Propose a parameterized dist $q$ that is easy to work with, and learn parameters $\\phi$ that approximates it.\n","\n","### In our case \n","\n","E.g. find $q(z) = \\mathcal{N}(z; \\mu, \\sigma^2)$      as close as possible to $p(z | x^{(i)})$\n","\n","### How?\n","\n","Minimize $\\mathrm{KL}$ divergence:\n","\n","$$\\min_{q(z)} \\mathrm{D_{KL}}(q(z) \\parallel p(z | x^{(i)})) $$\n","\n","$$ = \\min_{q(z)} \\mathop{\\mathbb{E}}_{z \\sim q(z)} \\log \\left( \\frac{q(z)}{ p(z | x^{(i)})}\\right) $$\n","$$ = \\min_{q(z)} \\mathop{\\mathbb{E}}_{z \\sim q(z)}\\left[ \\log {q(z)} - \\log p(z | x^{(i)}) \\right]$$\n","\n","$$ = \\min_{q(z)} \\mathop{\\mathbb{E}}_{z \\sim q(z)}\\left[ \\log {q(z)} - \\log \\left(\\frac{p_\\theta(x^{(i)} | z) p_Z(z)}{p_\\theta(x^{(i)})} \\right) \\right]$$\n","$$ = \\min_{q(z)} \\mathop{\\mathbb{E}}_{z \\sim q(z)}\\left[ \\log {q(z)} + \\log p_\\theta(x^{(i)}) - \\log p_\\theta(x^{(i)}| z) - \\log p_Z(z)\\right]$$\n","$$ = \\min_{q(z)} \\mathop{\\mathbb{E}}_{z \\sim q(z)}\\left[ \\log {q(z)} - \\log p_\\theta(x^{(i)}| z) - \\log p_Z(z)\\right]$$"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"DvSsiqQR6egU"},"source":["All the quantities in this objective are readily computable:\n","\n","* $q(z)$ is easy to compute by choice\n","* $p_Z(z)$ is also easy to compute by design\n","* $p_\\theta(x^{(i)} | z)$ is a neural network, and even though $\\theta$ may not be the final one, we can still compute it efficiently\n","\n","**Drawback**: We need to learn a $q$ separately fo **each** $x^{(i)}$"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"nqQQaSVz63b8"},"source":["## [Amortized Inference](https://www.youtube.com/watch?v=FMuvUZXMzKM&t=2092s)\n","\n","**We can do better!**\n","\n","<img src=\"https://www.evernote.com/l/Ags_LC-RXlhPXoxXd-2N7mFqhanpQrE50w4B/image.png\" alt=\"drawing\" width=\"300\"/>\n","\n","### Old objective\n","\n","$$\\min_{q(z)} \\mathrm{D_{KL}}(q(z) \\parallel p(z | x^{(i)})) $$\n","\n","This was being done per datapoint $x^{(i)}$\n","\n","### Amortized formulation\n","\n","Add all the things! Let a NN learn the reverse mapping $x \\rightarrow z$\n","\n","#### Amortized obective:\n","\n","$$\\min_\\phi \\sum_i \\mathrm{D_{KL}}\\left(q_\\phi(z | x^{(i)}) \\parallel p(z | x^{(i)}\\right)$$\n","\n","The old formulation required an optimization step per datapoint $x^{(i)}$ to find its corresponding $q$. With the new objective, we train a network $q_\\phi$ to learn this.\n","\n","**Tradeoffs**\n","\n","* +Faster\n","* +Regularized\n","* -Not as precise"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"5XeqSNyC63y3"},"source":["### Example\n","\n","We have an image $x$, and $q_\\phi(z | x) = \\mathcal{N}(\\mu_\\phi(x), \\sigma^2(x))$. Passing $x$ through $q$, returns a $\\mu$ and $\\sigma$ which tells us the distribution of the $z$ that $x$ was sampled from.\n","# [Importance Weighted AutoEncoder (IWAE)](https://youtu.be/FMuvUZXMzKM?t=2815)\n","\n","Combine all of the above:\n","\n","$$\\mathcal{L}_K = \\left[ \\sum_i \\log \\frac1K\\sum_{k=1}^K \\frac{p_Z(z^{(i)}_k)}{q_\\phi(z^{(i)}_k)}p_\\theta(x^{(i)} | z_k^{(i)})  - \\sum_i \\mathrm{KL}(q_\\phi(z | x^{(i)}) \\parallel p(z | x^{(i)})\\right]$$\n","\n","$$ \\max_{\\theta, \\phi} \\mathcal{L}_K $$\n","\n","With $z_k^{(i)} \\sim q_\\phi(z_k^{(i)})$ \n","\n","\n","**Theorem**\n","\n","$$\\log p(\\mathbf{x}) \\geq \\mathcal{L}_{K+1} \\geq \\mathcal{L}_K $$\n","\n","And \n","\n","$$\\log p(\\mathbf{x}) = \\lim_{k\\rightarrow \\infty} \\mathcal{L}_K $$\n","\n","# [VLB / ELBO](https://youtu.be/FMuvUZXMzKM?list=PLwRJQ4m4UJjPiJP3691u-qWwPGVKzSlNP)\n","\n","$$\\max_\\theta\\sum_i\\log p_\\theta(x^{(i)}) $$\n","\n","$$ = \\max_\\theta\\sum_i\\log\\left(\\sum_z \\frac{q(z)}{q(z)} p_z(z) p_\\theta(x^{(i)} | z) \\right) $$\n","\n","$$ =\\max_\\theta\\sum_i \\log \\left(\\mathop{\\mathrm{E}}_{z \\sim q(z)} \\left[\\frac{p_z(z)}{q(z)} p_\\theta(x^{(i)} | z)\\right]\\right) $$\n","\n","By Jensen's:\n","\n","$$ \\geq\\max_\\theta\\sum_i \\mathop{\\mathrm{E}}_{z \\sim q(z)} \\left[ \\log \\left(\\frac{p_z(z)}{q(z)} p_\\theta(x^{(i)} | z)\\right)\\right] $$\n","\n","$$ =\\max_\\theta\\sum_i \\mathop{\\mathrm{E}}_{z \\sim q(z)} \\left[ \\log(p_z(z)) + \\log(p_\\theta(x^{(i)} | z)) - \\log(q(z))\\right] $$\n","Equality is met when $ q(z) \\propto p_z(z)p_\\theta(x^{(i)} | z) \\propto p_\\theta(z | x^{(i)})$\n","## [Alternative derivation](https://youtu.be/FMuvUZXMzKM?list=PLwRJQ4m4UJjPiJP3691u-qWwPGVKzSlNP&t=3969)\n","$$D_{\\mathrm{KL}} = \\mathop{\\mathrm{E}}_{z \\sim q(z)} \\left[\\log(q(z)) - \\log(p(z|x))\\right]$$\n","$$ \\mathop{\\mathrm{E}}_{z \\sim q(z)} \\left[\\log(q(z)) - \n","\\log(p(z, x)) + \\log(p(x))\\right] $$\n","$$ \\mathop{\\mathrm{E}}_{z \\sim q(z)} \\left[\\log(q(z)) - \n","\\log(p(z, x)) \\right] + \\log(p(x)) $$\n","$$ \\mathop{\\mathrm{E}}_{z \\sim q(z)} \\left[\\log(q(z)) - \n","\\log(p(x | z)) - \\log(p(z)) \\right] + \\log(p(x)) $$\n","$$\\Rightarrow D_{\\mathrm{KL}}(q(z) \\parallel p(z|x)) = \\mathop{\\mathrm{E}}_{z \\sim q(z)} \\left[\\log(q(z)) - \n","\\log(p(x | z)) - \\log(p(z)) \\right] + \\log(p(x)) $$\n","Or\n","$$\\log(p(x)) = \n","\\mathop{\\mathrm{E}}_{z \\sim q(z)} \\left[\n","\\log(p(x | z)) + \\log(p(z)) - \\log(q(z)) \\right] \n","+ D_{\\mathrm{KL}}(q(z) \\parallel p(z|x)) $$\n","Therefore the VLB holds, and we have equality when $q(z) \\propto p(z | x)$\n","# [How to optimize an expectation?](https://youtu.be/FMuvUZXMzKM?list=PLwRJQ4m4UJjPiJP3691u-qWwPGVKzSlNP&t=4109)\n","Given something of the form\n","\n","$$\\max_\\phi\\mathrm{E}_{z \\sim q_\\phi(z))}\\left[f(z)\\right]$$\n","\n","### Naive approach\n","\n","Just sample $z^{(i)} \\sim q(z)$. However, then when we go to evaluate the gradient we have:\n","\n","$$\\nabla_\\phi\\left[\\frac1K\\sum_k f(z^{(k)})\\right] = 0 ??? \\quad\\text{no deps on}~ \\phi$$\n","\n","This is not true...\n","## Likelihood Ratio Gradient\n","\n","Expand expectation:\n","\n","$$\\nabla_\\phi \\left(\\mathrm{E}_{z \\sim q_\\phi(z)}[f(z)]\\right) \n","= \\sum_z \\nabla_\\phi q_\\phi(z) f(z) \\\\\n","= \\sum_z \\frac{q_\\phi(z)}{q_\\phi(z)}\\nabla_\\phi q_\\phi(z) f(z) $$\n","$$ = \\mathrm{E}_{z \\sim q_\\phi(z))}\\frac{\\nabla_\\phi q_\\phi(z)}{q_\\phi(z)} f(z) $$\n","\n","$$ = \\mathrm{E}_{z \\sim q_\\phi(z)} f(z) \\nabla_\\phi \\log q_\\phi(z) $$\n","$$ \\approx \\frac1K\\sum_i^K f(z^{(i)}) \\nabla_\\phi \\log q_\\phi(z^{(i)}) $$\n","Where $z{(i)} \\sim q_\\phi(z)$\n","\n","This works but is very noisy.\n","## Reparametrization trick\n","\n","In the case of specific distributions, we may be able to do better. \n","\n","E.g. in the case of a gaussian, $q_\\phi(z) = \\mathcal{N}(\\mu, \\sigma^2)$. Then we can write \n","\n","$$ z = \\mu + \\epsilon * \\sigma \\quad \\epsilon \\sim \\mathcal{N}(0, 1)$$\n","\n","$$ \\mathrm{E}_{z \\sim q_\\phi(z)} [f(z)] = \\mathrm{E}_{z \\sim q_\\phi(z)} [f(\\mu + \\epsilon \\sigma)] \\approx \\frac1K\\sum_i^K f(\\mu + \\epsilon\\sigma)$$\n","Then the gradient is \n","\n","$$ \\nabla_{\\mu,\\sigma} \\left(\\mathrm{E}_{z \\sim q_\\phi(z)}[f(z)]\\right) \\approx \n","\\nabla_{\\mu,\\sigma} \\frac1K\\sum_i^K f(\\mu + \\epsilon\\sigma) \n","= \\frac1K\\sum_i^K \\nabla_{\\mu, \\sigma} f(\\mu + \\epsilon^{(i)}\\sigma) \n","$$\n","This has **much lower variance** than the generic likelihood ratio gradient.\n","## In general\n","\n","* If the variables are continuous, we can use a flow to reparametrize/approximate the distribution that we're trying to sample from, and then we can optimize over it the way we did above.\n","\n","* Unsure what happens when the distribution is discrete. \n","# Optimizing VLB with Likelihood Ratio Gradient\n","\n","\n","$$\\max_{\\theta, \\phi} \\mathop{\\mathrm{E}}_{z \\sim q_\\phi(z | x^{(i)})} \\left[ \\log(p_z(z)) + \\log(p_\\theta(x^{(i)} | z)) - \\log(q_\\phi(z | x^{(i)}))\\right]$$\n","Gradient with respect to $\\theta$ is easy, we can just sample:\n","\n","$$= \\nabla_\\theta \\mathop{\\mathrm{E}}_{z \\sim q_\\phi(z | x^{(i)})} \n","\\left[ \\log p_\\theta(x^{(i)} | z)\\right]\n","\\approx \\nabla_\\theta \\frac1K\\sum_{k=1}^K \\log p_\\theta(x^{(i)} | z^{(k)})\\quad\\quad z^{(k)} \\sim q_\\phi(z | x^{(i)})\n","$$\n","Gradient with respect to $\\phi$:\n","\n","\n","$$ \n","\\nabla_\\phi \\mathop{\\mathrm{E}}_{z \\sim q_\\phi(z | x^{(i)})} \\left[ \n","\\log(p_z(z)) + \\log(p_\\theta(x^{(i)} | z)) - \\log(q_\\phi(z | x^{(i)}))\n","\\right]  \n","$$\n","Expand the expectation:\n","$$ \\approx \\nabla_\\phi \\sum_z q_\\phi(z | x^{(i)})\\left[  \n","\\log(p_z(z) + \\log(p_\\theta(x^{(i)} | z) - \\log(q_\\phi(z| x^{(i)}))\n","\\right]\n","$$\n","$$ \n","= \\sum_z \\nabla_\\phi q_\\phi(z | x^{(i)})\\left[  \n","\\log(p_z(z) + \\log(p_\\theta(x^{(i)} | z) - \\log(q_\\phi(z | x^{(i)}))\n","\\right] - q_\\phi(z | x^{(i)})\\nabla_\\phi \\log(q_\\phi(z | x^{(i)}))\n","$$\n","$$\n","= \\sum_z \\nabla_\\phi q_\\phi(z)\\left[  \n","\\log(p_z(z) + \\log(p_\\theta(x^{(i)} | z) - \\log(q_\\phi(z | x^{(i)}))\n","\\right] - q_\\phi(z | x^{(i)})\\frac{\\nabla_\\phi q_\\phi(z | x^{(i)})}{q_\\phi(z | x^{(i)})}\n","$$\n","$$\n","= \\sum_z \\nabla_\\phi q_\\phi(z\\left[  \n","\\log(p_z(z) + \\log(p_\\theta(x^{(i)} | z) - \\log(q_\\phi(z | x^{(i)}))\n","\\right] - \\nabla_\\phi q_\\phi(z | x^{(i)})\n","$$\n","$$\n","= \\sum_z \\nabla_\\phi q_\\phi(z\\left[  \n","\\log(p_z(z) + \\log(p_\\theta(x^{(i)} | z) - \\log(q_\\phi(z | x^{(i)}))\n","\\right] - \\nabla_\\phi \\sum_z q_\\phi(z | x^{(i)})\n","$$\n","And we know that for $z \\sim q_\\phi(z|x^{(i)})$, $\\sum_z q_\\phi(z | x^{(i)}) = 1$, and thus $\\nabla_\\phi\\sum_z q_\\phi(z | x^{(i)}) = 0$. Hence:\n","$$\n","= \\sum_z \\nabla_\\phi q_\\phi(z\\left[  \n","\\log(p_z(z) + \\log(p_\\theta(x^{(i)} | z) - \\log(q_\\phi(z | x^{(i)}))\n","\\right]\n","$$\n","So we don't have to worry about the extra term.\n","# Questions\n","\n","#### How does the [Likelihood Ratio Gradient Toy problem work](https://www.youtube.com/watch?v=FMuvUZXMzKM&list=PLwRJQ4m4UJjPiJP3691u-qWwPGVKzSlNP&index=4)? (the lecture has an error)\n","\n","<img src=\"https://www.evernote.com/l/Agsa9w8BCmRHOL2FCOrGW9dWKmln5evBNEwB/image.png\" alt=\"drawing\" width=\"500\"/>\n","\n","$$ \\approx \\frac1K\\sum_i^K f(z^{(i)}) \\left(\\frac12 (\\phi - z) \\right) $$\n","Therefore each term is moving in the direction $z \\rightarrow \\phi$ proportional to $f(z^{(i)})$. \n","\n","* Samples further away from the green point will contribute terms that point ~towards the green point, with a big coefficient\n","* Samples closer to the green point will contribute terms that point away from the green point with small coefficients. \n","* The average of all of the terms (when K is big) points to the green point.\n","* This process is fairly noisy.\n","#### [How does VAE and likelihood ratio gradient work?](https://youtu.be/FMuvUZXMzKM?list=PLwRJQ4m4UJjPiJP3691u-qWwPGVKzSlNP&t=5500)\n","  * Why do we get an \"additional term\"?: Just expand the expectation and apply the gradient there.\n","#### [How is the objective of the VAE derived?](https://youtu.be/FMuvUZXMzKM?list=PLwRJQ4m4UJjPiJP3691u-qWwPGVKzSlNP&t=6338)\n","\n","<img src=\"https://www.evernote.com/l/AgsRPHxedUdJjJ9jzNfbDILqMFnsqXmgZuMB/image.png\" alt=\"drawing\" width=\"500\"/>\n","\n","\n","#### Go over VQ-VAE\n","* [How does it actually work?](https://arxiv.org/pdf/1711.00937.pdf)\n"]}]}